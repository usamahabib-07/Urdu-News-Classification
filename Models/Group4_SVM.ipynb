{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7435c0e1-bbcb-4124-9da7-0a38050ee7fb",
   "metadata": {
    "id": "7435c0e1-bbcb-4124-9da7-0a38050ee7fb"
   },
   "source": [
    "# SVM implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1956033-ef07-4317-8dbb-50189fbfde4f",
   "metadata": {
    "id": "e1956033-ef07-4317-8dbb-50189fbfde4f"
   },
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb5c443-2484-42a3-b430-8c2f8cd951f3",
   "metadata": {
    "id": "dbb5c443-2484-42a3-b430-8c2f8cd951f3"
   },
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# PyTorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Miscellaneous\n",
    "import joblib\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd1e9c0-795a-4671-b057-04632c96b6fe",
   "metadata": {
    "id": "4fd1e9c0-795a-4671-b057-04632c96b6fe"
   },
   "source": [
    "### Load and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226f6f05-e0c6-4a19-9b5b-9fb64b180269",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "226f6f05-e0c6-4a19-9b5b-9fb64b180269",
    "outputId": "c4927004-90cf-44d3-d47c-9571df200606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "     id                                              title  \\\n",
      "0   526   یوٹیلیٹی اسٹورز پر چینی کی قیمت میں کمی کردی گئی   \n",
      "1  1462            ایڈیلیڈ میچ کے ہیرو حارث رؤف کی سالگرہ   \n",
      "2  1515  ’’پیگماٹائٹ‘‘ یہ نایاب پتھروں اور غیرمعمولی عن...   \n",
      "3  1656  جوبائیڈن کا ڈونلڈ ٹرمپ کو فون، جیت پر مبارک با...   \n",
      "4  1840             پاکستان میں آج سونے کی قیمت کیا رہی ؟   \n",
      "\n",
      "                                 link  \\\n",
      "0  https://urdu.geo.tv/latest/385946-   \n",
      "1    https://jang.com.pk/news/1409128   \n",
      "2    https://jang.com.pk/news/1309594   \n",
      "3    https://jang.com.pk/news/1408469   \n",
      "4    https://urdu.samaa.tv/2087324435   \n",
      "\n",
      "                                             content          gold_label  \\\n",
      "0  اسلام آباد: یوٹیلیٹی اسٹورز کارپوریشن نے چینی...            business   \n",
      "1  قومی کرکٹ ٹیم کے فاسٹ بولر اور آسٹریلیا کے خل...              sports   \n",
      "2  نایاب پتھروں یا انمول نگینوں کی تلاش اور پھر ح...  science-technology   \n",
      "3  امریکی صدر جوبائیڈن نے ری پبلکن پارٹی کے امیدو...       international   \n",
      "4  عالمی منڈی اور پاکستان بھر میں آج سونے کی قیم...            business   \n",
      "\n",
      "                                   processed_content  \n",
      "0  ['اسلام', 'آباد', 'یوٹیلیٹی', 'اسٹورز', 'کارپو...  \n",
      "1  ['قومی', 'کرکٹ', 'ٹیم', 'کے', 'فاسٹ', 'بولر', ...  \n",
      "2  ['نایاب', 'پتھروں', 'یا', 'انمول', 'نگینوں', '...  \n",
      "3  ['امریکی', 'صدر', 'جوبائیڈن', 'نے', 'ری', 'پبل...  \n",
      "4  ['عالمی', 'منڈی', 'اور', 'پاکستان', 'بھر', 'می...  \n",
      "\n",
      "Data types of each column:\n",
      "id                    int64\n",
      "title                object\n",
      "link                 object\n",
      "content              object\n",
      "gold_label           object\n",
      "processed_content    object\n",
      "dtype: object\n",
      "\n",
      "Missing values in each column:\n",
      "id                   0\n",
      "title                0\n",
      "link                 0\n",
      "content              0\n",
      "gold_label           0\n",
      "processed_content    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicated rows: 0\n",
      "Dataset shape after removing duplicates: (2281, 6)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your dataset\n",
    "data_path = 'normalized_and_tokenized_combined_data.xlsx'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nNumber of duplicated rows:\", df.duplicated().sum())\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "print(\"Dataset shape after removing duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25decb01-cd5f-48b8-b8bc-648a6059c5fd",
   "metadata": {
    "id": "25decb01-cd5f-48b8-b8bc-648a6059c5fd"
   },
   "source": [
    "### Data preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb332d-5c3b-49a2-a63d-2e295d848794",
   "metadata": {
    "id": "2feb332d-5c3b-49a2-a63d-2e295d848794"
   },
   "source": [
    "#### (i) Normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d61a10-b1ed-4be5-9103-756aec21b258",
   "metadata": {
    "id": "69d61a10-b1ed-4be5-9103-756aec21b258"
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalize Urdu text by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation\n",
    "    - Removing numbers\n",
    "    - Removing extra whitespace\n",
    "    \"\"\"\n",
    "    # Convert to string (in case of any non-string entries)\n",
    "    text = str(text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71b214-cbf1-4c32-a4b6-186169150c67",
   "metadata": {
    "id": "4d71b214-cbf1-4c32-a4b6-186169150c67"
   },
   "source": [
    "#### (ii) Tokenizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935065eb-39a4-4a79-b207-8fac3916bbec",
   "metadata": {
    "id": "935065eb-39a4-4a79-b207-8fac3916bbec"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenize the normalized text into words.\n",
    "    \"\"\"\n",
    "    # Split text by whitespace\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords (common words that are not useful for classification)\n",
    "    # this is a smaller set of stopwords, we have uploaded another larger list on the GitHub\n",
    "    # which is more comprehensive\n",
    "    stopwords_urdu = set([\n",
    "        'اور', 'میں', 'کو', 'کا', 'کی', 'کیوں', 'ہو', 'ہیں', 'ہوں', 'یہ', 'وہ',\n",
    "        'وہاں', 'تھا', 'تھی', 'تھے', 'کر', 'کرنے',\n",
    "        'کیا', 'ہوتا', 'ہوتی', 'ہوتے', 'گا', 'گی', 'گے', 'جائے', 'جانا'\n",
    "    ])\n",
    "\n",
    "    tokens = [token for token in tokens if token not in stopwords_urdu]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e2451-9b42-4daa-833c-0632289c08b9",
   "metadata": {
    "id": "d73e2451-9b42-4daa-833c-0632289c08b9"
   },
   "source": [
    "#### Apply normalization and tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57bdaca1-934e-46e6-abd5-0c525753ef28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57bdaca1-934e-46e6-abd5-0c525753ef28",
    "outputId": "e7493e0d-54df-4304-82c3-79a37898b7d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of processed content:\n",
      "                                             content  \\\n",
      "0  اسلام آباد: یوٹیلیٹی اسٹورز کارپوریشن نے چینی...   \n",
      "1  قومی کرکٹ ٹیم کے فاسٹ بولر اور آسٹریلیا کے خل...   \n",
      "2  نایاب پتھروں یا انمول نگینوں کی تلاش اور پھر ح...   \n",
      "3  امریکی صدر جوبائیڈن نے ری پبلکن پارٹی کے امیدو...   \n",
      "4  عالمی منڈی اور پاکستان بھر میں آج سونے کی قیم...   \n",
      "\n",
      "                                   processed_content  \n",
      "0  [اسلام, آباد, یوٹیلیٹی, اسٹورز, کارپوریشن, نے...  \n",
      "1  [قومی, کرکٹ, ٹیم, کے, فاسٹ, بولر, آسٹریلیا, ک...  \n",
      "2  [نایاب, پتھروں, یا, انمول, نگینوں, تلاش, پھر, ...  \n",
      "3  [امریکی, صدر, جوبائیڈن, نے, ری, پبلکن, پارٹی, ...  \n",
      "4  [عالمی, منڈی, پاکستان, بھر, آج, سونے, قیمت, ب...  \n"
     ]
    }
   ],
   "source": [
    "# Apply normalization\n",
    "df['normalized_content'] = df['content'].apply(normalize_text)\n",
    "\n",
    "# Apply tokenization\n",
    "df['processed_content'] = df['normalized_content'].apply(tokenize_text)\n",
    "\n",
    "# Verify the preprocessing\n",
    "print(\"\\nSample of processed content:\")\n",
    "print(df[['content', 'processed_content']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602aad1b-3562-4fee-8420-b034ea17ce95",
   "metadata": {
    "id": "602aad1b-3562-4fee-8420-b034ea17ce95"
   },
   "source": [
    "### Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc35c12-a18a-4de5-bc95-2d3eb22c83c9",
   "metadata": {
    "id": "0cc35c12-a18a-4de5-bc95-2d3eb22c83c9"
   },
   "outputs": [],
   "source": [
    "class CustomTFIDF:\n",
    "    def __init__(self, min_df=2, max_df=0.95, ngram_range=(1,1)):\n",
    "        \"\"\"\n",
    "        Initialize the CustomTFIDF vectorizer.\n",
    "\n",
    "        Args:\n",
    "            min_df (int): Minimum document frequency.\n",
    "            max_df (float): Maximum document frequency (as a fraction).\n",
    "            ngram_range (tuple): The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "        \"\"\"\n",
    "        self.min_df = min_df\n",
    "        self.max_df = max_df\n",
    "        self.ngram_range = ngram_range\n",
    "        self.vocabulary_ = {}\n",
    "        self.idf_ = {}\n",
    "\n",
    "    def _generate_ngrams(self, tokens):\n",
    "        \"\"\"\n",
    "        Generate n-grams from tokens based on the specified ngram_range.\n",
    "        \"\"\"\n",
    "        lower, upper = self.ngram_range\n",
    "        ngrams = []\n",
    "        for n in range(lower, upper + 1):\n",
    "            ngrams += [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "        return ngrams\n",
    "\n",
    "    def fit(self, documents):\n",
    "        \"\"\"\n",
    "        Learn vocabulary and idf from the training documents.\n",
    "        \"\"\"\n",
    "        df_counts = defaultdict(int)  # Document frequency for each term\n",
    "        total_docs = len(documents)\n",
    "\n",
    "        for doc in documents:\n",
    "            terms = set(self._generate_ngrams(doc))\n",
    "            for term in terms:\n",
    "                df_counts[term] += 1\n",
    "\n",
    "        # Apply min_df and max_df\n",
    "        filtered_terms = [term for term, count in df_counts.items()\n",
    "                         if count >= self.min_df and (count / total_docs) <= self.max_df]\n",
    "\n",
    "        # Assign indices to terms\n",
    "        self.vocabulary_ = {term: idx for idx, term in enumerate(filtered_terms)}\n",
    "\n",
    "        # Calculate idf for each term\n",
    "        self.idf_ = {term: np.log((1 + total_docs) / (1 + df_counts[term])) + 1 for term in self.vocabulary_}\n",
    "\n",
    "    def transform(self, documents):\n",
    "        \"\"\"\n",
    "        Transform documents to TF-IDF matrix.\n",
    "        \"\"\"\n",
    "        rows = len(documents)\n",
    "        cols = len(self.vocabulary_)\n",
    "        tfidf_matrix = np.zeros((rows, cols))\n",
    "\n",
    "        for i, doc in enumerate(documents):\n",
    "            terms = self._generate_ngrams(doc)\n",
    "            term_counts = defaultdict(int)\n",
    "            for term in terms:\n",
    "                if term in self.vocabulary_:\n",
    "                    term_counts[term] += 1\n",
    "            total_terms = len(terms)\n",
    "            for term, count in term_counts.items():\n",
    "                tf = count / total_terms\n",
    "                idf = self.idf_[term]\n",
    "                tfidf_matrix[i, self.vocabulary_[term]] = tf * idf\n",
    "\n",
    "        return tfidf_matrix\n",
    "\n",
    "    def fit_transform(self, documents):\n",
    "        \"\"\"\n",
    "        Fit to data, then transform it.\n",
    "        \"\"\"\n",
    "        self.fit(documents)\n",
    "        return self.transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eefbb8a-6f1f-42bc-be8d-0426c164258f",
   "metadata": {
    "id": "4eefbb8a-6f1f-42bc-be8d-0426c164258f"
   },
   "source": [
    "### Perform train-test split (without `sklearn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318305af-0a03-4469-99bd-419c164655e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "318305af-0a03-4469-99bd-419c164655e0",
    "outputId": "438ddf73-d1f0-4176-9fff-b23ed735da5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1825, 7)\n",
      "Testing set shape: (456, 7)\n"
     ]
    }
   ],
   "source": [
    "def manual_train_test_split(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into training and testing sets manually.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The complete DataFrame.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        random_state (int): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame, pd.DataFrame: Training and testing DataFrames.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    test_count = int(len(df) * test_size)\n",
    "    test_indices = shuffled_indices[:test_count]\n",
    "    train_indices = shuffled_indices[test_count:]\n",
    "\n",
    "    train_df = df.iloc[train_indices].reset_index(drop=True)\n",
    "    test_df = df.iloc[test_indices].reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# Perform the split\n",
    "train_df, test_df = manual_train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Testing set shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79fe31-deb6-4278-9086-064be93c51d6",
   "metadata": {
    "id": "5f79fe31-deb6-4278-9086-064be93c51d6"
   },
   "source": [
    "#### Initialize and fit the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5044631-3f77-4a98-a69a-53153f0aa72b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5044631-3f77-4a98-a69a-53153f0aa72b",
    "outputId": "de4de538-783d-4597-9b2a-534b5c32d7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom TF-IDF matrix shape:\n",
      "X_train: (1825, 100329)\n",
      "X_test: (456, 100329)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CustomTFIDF vectorizer\n",
    "custom_tfidf = CustomTFIDF(min_df=2, max_df=0.95, ngram_range=(1,3)) \n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = custom_tfidf.fit_transform(train_df['processed_content'])\n",
    "\n",
    "# Transform the testing data\n",
    "X_test = custom_tfidf.transform(test_df['processed_content'])\n",
    "\n",
    "print(\"Custom TF-IDF matrix shape:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9380db-20ec-4b0f-bd93-5f89b28f5e17",
   "metadata": {
    "id": "1e9380db-20ec-4b0f-bd93-5f89b28f5e17"
   },
   "source": [
    "### Encode labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef3ef21-1d93-4e31-9203-d1244da94cdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ef3ef21-1d93-4e31-9203-d1244da94cdf",
    "outputId": "6e7e163c-475a-4d0f-de55-eb3e4a8a5323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Encoding Mapping:\n",
      "{'business': 0, 'entertainment': 1, 'international': 2, 'science-technology': 3, 'sports': 4}\n"
     ]
    }
   ],
   "source": [
    "def encode_labels(labels):\n",
    "    \"\"\"\n",
    "    Encode string labels to integers.\n",
    "\n",
    "    Args:\n",
    "        labels (pd.Series): Series of string labels.\n",
    "\n",
    "    Returns:\n",
    "        np.array, dict: Encoded labels and a mapping dictionary.\n",
    "    \"\"\"\n",
    "    unique_labels = sorted(labels.unique())\n",
    "    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    int_to_label = {idx: label for label, idx in label_to_int.items()}\n",
    "    encoded_labels = labels.map(label_to_int).values\n",
    "    return encoded_labels, label_to_int, int_to_label\n",
    "\n",
    "# Encode labels for training and testing sets\n",
    "y_train, label_to_int, int_to_label = encode_labels(train_df['gold_label'])\n",
    "y_test = test_df['gold_label'].map(label_to_int).values\n",
    "\n",
    "print(\"\\nLabel Encoding Mapping:\")\n",
    "print(label_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba530b8c-145b-4232-bcb6-a130b1a198a3",
   "metadata": {
    "id": "ba530b8c-145b-4232-bcb6-a130b1a198a3"
   },
   "source": [
    "### Compute class weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade9814d-ac7c-4a6a-83b7-98db4260dc03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ade9814d-ac7c-4a6a-83b7-98db4260dc03",
    "outputId": "dbc4cdde-653b-461d-e5cc-57ec5ce0a63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Weights: [1.01364413 0.9889211  1.0052669  1.01646765 0.97570023]\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(y, num_classes):\n",
    "    \"\"\"\n",
    "    Compute class weights inversely proportional to class frequencies.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Array of encoded labels.\n",
    "        num_classes (int): Number of unique classes.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array of class weights.\n",
    "    \"\"\"\n",
    "    class_counts = np.bincount(y, minlength=num_classes)\n",
    "    class_weights = 1.0 / (class_counts + 1e-6)  # Adding a small value to avoid division by zero\n",
    "    normalized_weights = class_weights / class_weights.sum() * num_classes  # Normalize weights\n",
    "    return normalized_weights\n",
    "\n",
    "num_classes = len(label_to_int)\n",
    "class_weights = compute_class_weights(y_train, num_classes)\n",
    "print(\"\\nClass Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea945b-6967-408d-a1e7-b55fd36edb00",
   "metadata": {
    "id": "ffea945b-6967-408d-a1e7-b55fd36edb00"
   },
   "source": [
    "#### Define a custom Pytorch dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d7241f-d9e4-415a-839b-fed7d45d7345",
   "metadata": {
    "id": "21d7241f-d9e4-415a-839b-fed7d45d7345"
   },
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features (np.array): TF-IDF feature matrix.\n",
    "            labels (np.array): Corresponding labels.\n",
    "        \"\"\"\n",
    "        self.X = torch.tensor(features, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a1085-cbea-42be-908d-9f8fe185d18a",
   "metadata": {
    "id": "ce1a1085-cbea-42be-908d-9f8fe185d18a"
   },
   "source": [
    "#### Create a Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98f1216-23d5-439b-8316-1362252459e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c98f1216-23d5-439b-8316-1362252459e1",
    "outputId": "d45df1ba-bba7-4b79-97a7-5830cf69f547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training batches: 58\n",
      "Number of testing batches: 15\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset instances\n",
    "train_dataset = NewsDataset(X_train, y_train)\n",
    "test_dataset = NewsDataset(X_test, y_test)\n",
    "\n",
    "# Define DataLoader parameters\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nNumber of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of testing batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8fcaa9-d3ef-4387-9558-66b0a9d0f44c",
   "metadata": {
    "id": "4a8fcaa9-d3ef-4387-9558-66b0a9d0f44c"
   },
   "source": [
    "## SVM implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d357a162-069b-4115-b484-92376d9d993a",
   "metadata": {
    "id": "d357a162-069b-4115-b484-92376d9d993a"
   },
   "outputs": [],
   "source": [
    "class SVM(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, C=1.0):\n",
    "        super(SVM, self).__init__()\n",
    "        # Single linear layer for the SVM\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "        # Regularization parameter\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear output\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca54f25-b59c-43f6-a292-e65a77831798",
   "metadata": {
    "id": "bca54f25-b59c-43f6-a292-e65a77831798"
   },
   "source": [
    "#### Initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17fa65e-b08d-41b0-8f38-8a932a5dfaec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c17fa65e-b08d-41b0-8f38-8a932a5dfaec",
    "outputId": "4f1daa02-aae2-482e-87b6-c20ecade0a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Architecture:\n",
      "SVM(\n",
      "  (fc): Linear(in_features=100329, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "input_size = X_train.shape[1]  # Number of TF-IDF features\n",
    "num_classes = 5\n",
    "C = 5.0\n",
    "\n",
    "model = SVM(input_size, num_classes, C)\n",
    "print(\"\\nSVM Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8df44e-a32d-4b6a-9e67-a049ad023477",
   "metadata": {
    "id": "6c8df44e-a32d-4b6a-9e67-a049ad023477"
   },
   "source": [
    "### Train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1951e4-eece-4d1b-8f3b-704479e018f1",
   "metadata": {
    "id": "0b1951e4-eece-4d1b-8f3b-704479e018f1"
   },
   "source": [
    "#### Check if GPU available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e838f04f-c3fa-44a9-a97c-865c2465388d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e838f04f-c3fa-44a9-a97c-865c2465388d",
    "outputId": "dc399ec5-86a4-45cd-a742-7d0ffb3e2b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVM(\n",
       "  (fc): Linear(in_features=100329, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bfae0b-b3f9-4cf5-807c-ee946e94e76f",
   "metadata": {
    "id": "48bfae0b-b3f9-4cf5-807c-ee946e94e76f"
   },
   "source": [
    "#### Define loss function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98390c4c-e439-4856-8091-e83cbef4b8f4",
   "metadata": {
    "id": "98390c4c-e439-4856-8091-e83cbef4b8f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\habib\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self, C=1.0, class_weights=None):\n",
    "        super(HingeLoss, self).__init__()\n",
    "        self.C = C\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=outputs.shape[1]).float()\n",
    "        margin = 1 - torch.sum(labels_one_hot * outputs, dim=1)\n",
    "        hinge_loss = torch.mean(torch.clamp(margin, min=0))\n",
    "\n",
    "        # Add regularization (weights and bias)\n",
    "        regularization = 0.5 * torch.sum(model.fc.weight ** 2) + 0.5 * torch.sum(model.fc.bias ** 2)\n",
    "\n",
    "        # Adjust for class weights if provided\n",
    "        if self.class_weights is not None:\n",
    "            weights = self.class_weights[labels]\n",
    "            hinge_loss = torch.mean(torch.clamp(margin, min=0) * weights)\n",
    "\n",
    "        return regularization + self.C * hinge_loss\n",
    "\n",
    "# Extract labels from the train loader\n",
    "y_train = np.array([label.item() for _, label in train_loader.dataset])\n",
    "\n",
    "# Ensure classes contain all unique labels in y_train\n",
    "unique_classes = np.unique(y_train)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train)\n",
    "class_weights = np.sqrt(class_weights)  # Reduce impact by taking square root\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = HingeLoss(C=C, class_weights=class_weights)\n",
    "\n",
    "# Define optimizer with weight decay for L2 regularization\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.95, weight_decay=0.001)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91fd3c-b5d1-4190-868a-372f4567326e",
   "metadata": {
    "id": "5b91fd3c-b5d1-4190-868a-372f4567326e"
   },
   "source": [
    "#### Training loop (with early stopping):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c484ab74-d102-4be6-b8ca-5537b49b1924",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c484ab74-d102-4be6-b8ca-5537b49b1924",
    "outputId": "bedf4ee8-f204-47e8-a9f2-63fca9df81f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] Train Loss: 5.6335, Train Acc: 0.1764 Val Loss: 5.3313, Val Acc: 0.2061\n",
      "Epoch [2/1000] Train Loss: 5.0310, Train Acc: 0.2000 Val Loss: 4.7332, Val Acc: 0.2149\n",
      "Epoch [3/1000] Train Loss: 4.4899, Train Acc: 0.2066 Val Loss: 4.2532, Val Acc: 0.1974\n",
      "EarlyStopping counter: 1 out of 200\n",
      "Epoch [4/1000] Train Loss: 4.0611, Train Acc: 0.2460 Val Loss: 3.8763, Val Acc: 0.1974\n",
      "EarlyStopping counter: 2 out of 200\n",
      "Epoch [5/1000] Train Loss: 3.7241, Train Acc: 0.2033 Val Loss: 3.5803, Val Acc: 0.1886\n",
      "EarlyStopping counter: 3 out of 200\n",
      "Epoch [6/1000] Train Loss: 3.4601, Train Acc: 0.2022 Val Loss: 3.3481, Val Acc: 0.1886\n",
      "EarlyStopping counter: 4 out of 200\n",
      "Epoch [7/1000] Train Loss: 3.2526, Train Acc: 0.2022 Val Loss: 3.1666, Val Acc: 0.1886\n",
      "EarlyStopping counter: 5 out of 200\n",
      "Epoch [8/1000] Train Loss: 3.0900, Train Acc: 0.2022 Val Loss: 3.0235, Val Acc: 0.1886\n",
      "EarlyStopping counter: 6 out of 200\n",
      "Epoch [9/1000] Train Loss: 2.9616, Train Acc: 0.2022 Val Loss: 2.9114, Val Acc: 0.1886\n",
      "EarlyStopping counter: 7 out of 200\n",
      "Epoch [10/1000] Train Loss: 2.8610, Train Acc: 0.2022 Val Loss: 2.8226, Val Acc: 0.1886\n",
      "EarlyStopping counter: 8 out of 200\n",
      "Epoch [11/1000] Train Loss: 2.7822, Train Acc: 0.2022 Val Loss: 2.7521, Val Acc: 0.1886\n",
      "EarlyStopping counter: 9 out of 200\n",
      "Epoch [12/1000] Train Loss: 2.7200, Train Acc: 0.2022 Val Loss: 2.6974, Val Acc: 0.1886\n",
      "EarlyStopping counter: 10 out of 200\n",
      "Epoch [13/1000] Train Loss: 2.6715, Train Acc: 0.2033 Val Loss: 2.6550, Val Acc: 0.2018\n",
      "EarlyStopping counter: 11 out of 200\n",
      "Epoch [14/1000] Train Loss: 2.6334, Train Acc: 0.2022 Val Loss: 2.6221, Val Acc: 0.1886\n",
      "EarlyStopping counter: 12 out of 200\n",
      "Epoch [15/1000] Train Loss: 2.6038, Train Acc: 0.2022 Val Loss: 2.5948, Val Acc: 0.1886\n",
      "EarlyStopping counter: 13 out of 200\n",
      "Epoch [16/1000] Train Loss: 2.5796, Train Acc: 0.2022 Val Loss: 2.5726, Val Acc: 0.1886\n",
      "EarlyStopping counter: 14 out of 200\n",
      "Epoch [17/1000] Train Loss: 2.5616, Train Acc: 0.2022 Val Loss: 2.5572, Val Acc: 0.1886\n",
      "EarlyStopping counter: 15 out of 200\n",
      "Epoch [18/1000] Train Loss: 2.5467, Train Acc: 0.2022 Val Loss: 2.5438, Val Acc: 0.1886\n",
      "EarlyStopping counter: 16 out of 200\n",
      "Epoch [19/1000] Train Loss: 2.5352, Train Acc: 0.2022 Val Loss: 2.5325, Val Acc: 0.1886\n",
      "EarlyStopping counter: 17 out of 200\n",
      "Epoch [20/1000] Train Loss: 2.5262, Train Acc: 0.2022 Val Loss: 2.5241, Val Acc: 0.1886\n",
      "EarlyStopping counter: 18 out of 200\n",
      "Epoch [21/1000] Train Loss: 2.5193, Train Acc: 0.2022 Val Loss: 2.5172, Val Acc: 0.1886\n",
      "EarlyStopping counter: 19 out of 200\n",
      "Epoch [22/1000] Train Loss: 2.5139, Train Acc: 0.2932 Val Loss: 2.5119, Val Acc: 0.2149\n",
      "EarlyStopping counter: 20 out of 200\n",
      "Epoch [23/1000] Train Loss: 2.5095, Train Acc: 0.2301 Val Loss: 2.5093, Val Acc: 0.1886\n",
      "EarlyStopping counter: 21 out of 200\n",
      "Epoch [24/1000] Train Loss: 2.5059, Train Acc: 0.2652 Val Loss: 2.5067, Val Acc: 0.3443\n",
      "Epoch [25/1000] Train Loss: 2.5031, Train Acc: 0.2214 Val Loss: 2.5055, Val Acc: 0.1842\n",
      "EarlyStopping counter: 1 out of 200\n",
      "Epoch [26/1000] Train Loss: 2.5012, Train Acc: 0.2049 Val Loss: 2.5044, Val Acc: 0.1842\n",
      "EarlyStopping counter: 2 out of 200\n",
      "Epoch [27/1000] Train Loss: 2.4994, Train Acc: 0.2049 Val Loss: 2.5040, Val Acc: 0.1842\n",
      "EarlyStopping counter: 3 out of 200\n",
      "Epoch [28/1000] Train Loss: 2.4991, Train Acc: 0.2049 Val Loss: 2.5033, Val Acc: 0.1842\n",
      "EarlyStopping counter: 4 out of 200\n",
      "Epoch [29/1000] Train Loss: 2.4976, Train Acc: 0.2049 Val Loss: 2.5029, Val Acc: 0.1842\n",
      "EarlyStopping counter: 5 out of 200\n",
      "Epoch [30/1000] Train Loss: 2.4965, Train Acc: 0.2049 Val Loss: 2.5020, Val Acc: 0.1842\n",
      "EarlyStopping counter: 6 out of 200\n",
      "Epoch [31/1000] Train Loss: 2.4958, Train Acc: 0.2049 Val Loss: 2.5005, Val Acc: 0.1842\n",
      "EarlyStopping counter: 7 out of 200\n",
      "Epoch [32/1000] Train Loss: 2.4952, Train Acc: 0.2049 Val Loss: 2.4990, Val Acc: 0.1842\n",
      "EarlyStopping counter: 8 out of 200\n",
      "Epoch [33/1000] Train Loss: 2.4948, Train Acc: 0.2049 Val Loss: 2.4988, Val Acc: 0.1842\n",
      "EarlyStopping counter: 9 out of 200\n",
      "Epoch [34/1000] Train Loss: 2.4947, Train Acc: 0.2049 Val Loss: 2.4987, Val Acc: 0.1842\n",
      "EarlyStopping counter: 10 out of 200\n",
      "Epoch [35/1000] Train Loss: 2.4946, Train Acc: 0.2049 Val Loss: 2.4986, Val Acc: 0.1842\n",
      "EarlyStopping counter: 11 out of 200\n",
      "Epoch [36/1000] Train Loss: 2.4946, Train Acc: 0.2049 Val Loss: 2.4982, Val Acc: 0.1842\n",
      "EarlyStopping counter: 12 out of 200\n",
      "Epoch [37/1000] Train Loss: 2.4947, Train Acc: 0.2433 Val Loss: 2.4978, Val Acc: 0.2368\n",
      "EarlyStopping counter: 13 out of 200\n",
      "Epoch [38/1000] Train Loss: 2.4943, Train Acc: 0.2729 Val Loss: 2.4969, Val Acc: 0.2325\n",
      "EarlyStopping counter: 14 out of 200\n",
      "Epoch [39/1000] Train Loss: 2.4939, Train Acc: 0.2153 Val Loss: 2.4969, Val Acc: 0.1864\n",
      "EarlyStopping counter: 15 out of 200\n",
      "Epoch [40/1000] Train Loss: 2.4940, Train Acc: 0.2948 Val Loss: 2.4976, Val Acc: 0.3377\n",
      "EarlyStopping counter: 16 out of 200\n",
      "Epoch [41/1000] Train Loss: 2.4939, Train Acc: 0.3205 Val Loss: 2.4970, Val Acc: 0.2675\n",
      "EarlyStopping counter: 17 out of 200\n",
      "Epoch [42/1000] Train Loss: 2.4938, Train Acc: 0.4471 Val Loss: 2.4968, Val Acc: 0.4057\n",
      "Epoch [43/1000] Train Loss: 2.4939, Train Acc: 0.2652 Val Loss: 2.4961, Val Acc: 0.2193\n",
      "EarlyStopping counter: 1 out of 200\n",
      "Epoch [44/1000] Train Loss: 2.4939, Train Acc: 0.2504 Val Loss: 2.4952, Val Acc: 0.2719\n",
      "EarlyStopping counter: 2 out of 200\n",
      "Epoch [45/1000] Train Loss: 2.4938, Train Acc: 0.2532 Val Loss: 2.4954, Val Acc: 0.1842\n",
      "EarlyStopping counter: 3 out of 200\n",
      "Epoch [46/1000] Train Loss: 2.4935, Train Acc: 0.3918 Val Loss: 2.4948, Val Acc: 0.3333\n",
      "EarlyStopping counter: 4 out of 200\n",
      "Epoch [47/1000] Train Loss: 2.4935, Train Acc: 0.3353 Val Loss: 2.4949, Val Acc: 0.2807\n",
      "EarlyStopping counter: 5 out of 200\n",
      "Epoch [48/1000] Train Loss: 2.4936, Train Acc: 0.3951 Val Loss: 2.4949, Val Acc: 0.4364\n",
      "Epoch [49/1000] Train Loss: 2.4934, Train Acc: 0.5775 Val Loss: 2.4942, Val Acc: 0.6425\n",
      "Epoch [50/1000] Train Loss: 2.4935, Train Acc: 0.3874 Val Loss: 2.4936, Val Acc: 0.3092\n",
      "EarlyStopping counter: 1 out of 200\n",
      "Epoch [51/1000] Train Loss: 2.4935, Train Acc: 0.3047 Val Loss: 2.4943, Val Acc: 0.2412\n",
      "EarlyStopping counter: 2 out of 200\n",
      "Epoch [52/1000] Train Loss: 2.4937, Train Acc: 0.3704 Val Loss: 2.4951, Val Acc: 0.4013\n",
      "EarlyStopping counter: 3 out of 200\n",
      "Epoch [53/1000] Train Loss: 2.4935, Train Acc: 0.3244 Val Loss: 2.4949, Val Acc: 0.4232\n",
      "EarlyStopping counter: 4 out of 200\n",
      "Epoch [54/1000] Train Loss: 2.4936, Train Acc: 0.5014 Val Loss: 2.4948, Val Acc: 0.4211\n",
      "EarlyStopping counter: 5 out of 200\n",
      "Epoch [55/1000] Train Loss: 2.4935, Train Acc: 0.3227 Val Loss: 2.4946, Val Acc: 0.2500\n",
      "EarlyStopping counter: 6 out of 200\n",
      "Epoch [56/1000] Train Loss: 2.4936, Train Acc: 0.2192 Val Loss: 2.4946, Val Acc: 0.1842\n",
      "EarlyStopping counter: 7 out of 200\n",
      "Epoch [57/1000] Train Loss: 2.4935, Train Acc: 0.2115 Val Loss: 2.4946, Val Acc: 0.2127\n",
      "EarlyStopping counter: 8 out of 200\n",
      "Epoch [58/1000] Train Loss: 2.4933, Train Acc: 0.3951 Val Loss: 2.4947, Val Acc: 0.3772\n",
      "EarlyStopping counter: 9 out of 200\n",
      "Epoch [59/1000] Train Loss: 2.4933, Train Acc: 0.2186 Val Loss: 2.4950, Val Acc: 0.1842\n",
      "EarlyStopping counter: 10 out of 200\n",
      "Epoch [60/1000] Train Loss: 2.4933, Train Acc: 0.2055 Val Loss: 2.4947, Val Acc: 0.1864\n",
      "EarlyStopping counter: 11 out of 200\n",
      "Epoch [61/1000] Train Loss: 2.4933, Train Acc: 0.3545 Val Loss: 2.4945, Val Acc: 0.2390\n",
      "EarlyStopping counter: 12 out of 200\n",
      "Epoch [62/1000] Train Loss: 2.4934, Train Acc: 0.3304 Val Loss: 2.4939, Val Acc: 0.2697\n",
      "EarlyStopping counter: 13 out of 200\n",
      "Epoch [63/1000] Train Loss: 2.4933, Train Acc: 0.3375 Val Loss: 2.4940, Val Acc: 0.3860\n",
      "EarlyStopping counter: 14 out of 200\n",
      "Epoch [64/1000] Train Loss: 2.4932, Train Acc: 0.5249 Val Loss: 2.4941, Val Acc: 0.6425\n",
      "EarlyStopping counter: 15 out of 200\n",
      "Epoch [65/1000] Train Loss: 2.4932, Train Acc: 0.3403 Val Loss: 2.4943, Val Acc: 0.1974\n",
      "EarlyStopping counter: 16 out of 200\n",
      "Epoch [66/1000] Train Loss: 2.4932, Train Acc: 0.3189 Val Loss: 2.4942, Val Acc: 0.3092\n",
      "EarlyStopping counter: 17 out of 200\n",
      "Epoch [67/1000] Train Loss: 2.4932, Train Acc: 0.2981 Val Loss: 2.4942, Val Acc: 0.2412\n",
      "EarlyStopping counter: 18 out of 200\n",
      "Epoch [68/1000] Train Loss: 2.4932, Train Acc: 0.2482 Val Loss: 2.4942, Val Acc: 0.1974\n",
      "EarlyStopping counter: 19 out of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/1000] Train Loss: 2.4931, Train Acc: 0.2230 Val Loss: 2.4943, Val Acc: 0.1996\n",
      "EarlyStopping counter: 20 out of 200\n",
      "Epoch [70/1000] Train Loss: 2.4931, Train Acc: 0.2405 Val Loss: 2.4943, Val Acc: 0.2061\n",
      "EarlyStopping counter: 21 out of 200\n",
      "Epoch [71/1000] Train Loss: 2.4932, Train Acc: 0.2395 Val Loss: 2.4944, Val Acc: 0.2171\n",
      "EarlyStopping counter: 22 out of 200\n",
      "Epoch [72/1000] Train Loss: 2.4931, Train Acc: 0.2214 Val Loss: 2.4945, Val Acc: 0.2105\n",
      "EarlyStopping counter: 23 out of 200\n",
      "Epoch [73/1000] Train Loss: 2.4931, Train Acc: 0.2438 Val Loss: 2.4943, Val Acc: 0.2390\n",
      "EarlyStopping counter: 24 out of 200\n",
      "Epoch [74/1000] Train Loss: 2.4931, Train Acc: 0.2789 Val Loss: 2.4944, Val Acc: 0.2566\n",
      "EarlyStopping counter: 25 out of 200\n",
      "Epoch [75/1000] Train Loss: 2.4931, Train Acc: 0.3359 Val Loss: 2.4944, Val Acc: 0.2654\n",
      "EarlyStopping counter: 26 out of 200\n",
      "Epoch [76/1000] Train Loss: 2.4931, Train Acc: 0.3036 Val Loss: 2.4944, Val Acc: 0.2412\n",
      "EarlyStopping counter: 27 out of 200\n",
      "Epoch [77/1000] Train Loss: 2.4931, Train Acc: 0.3085 Val Loss: 2.4943, Val Acc: 0.2412\n",
      "EarlyStopping counter: 28 out of 200\n",
      "Epoch [78/1000] Train Loss: 2.4931, Train Acc: 0.2323 Val Loss: 2.4944, Val Acc: 0.1996\n",
      "EarlyStopping counter: 29 out of 200\n",
      "Epoch [79/1000] Train Loss: 2.4931, Train Acc: 0.2767 Val Loss: 2.4943, Val Acc: 0.2346\n",
      "EarlyStopping counter: 30 out of 200\n",
      "Epoch [80/1000] Train Loss: 2.4931, Train Acc: 0.2384 Val Loss: 2.4944, Val Acc: 0.1996\n",
      "EarlyStopping counter: 31 out of 200\n",
      "Epoch [81/1000] Train Loss: 2.4931, Train Acc: 0.2208 Val Loss: 2.4944, Val Acc: 0.1952\n",
      "EarlyStopping counter: 32 out of 200\n",
      "Epoch [82/1000] Train Loss: 2.4931, Train Acc: 0.2285 Val Loss: 2.4944, Val Acc: 0.2061\n",
      "EarlyStopping counter: 33 out of 200\n",
      "Epoch [83/1000] Train Loss: 2.4931, Train Acc: 0.2427 Val Loss: 2.4943, Val Acc: 0.2105\n",
      "EarlyStopping counter: 34 out of 200\n",
      "Epoch [84/1000] Train Loss: 2.4931, Train Acc: 0.2444 Val Loss: 2.4943, Val Acc: 0.2237\n",
      "EarlyStopping counter: 35 out of 200\n",
      "Epoch [85/1000] Train Loss: 2.4931, Train Acc: 0.2685 Val Loss: 2.4943, Val Acc: 0.2544\n",
      "EarlyStopping counter: 36 out of 200\n",
      "Epoch [86/1000] Train Loss: 2.4931, Train Acc: 0.2844 Val Loss: 2.4943, Val Acc: 0.2610\n",
      "EarlyStopping counter: 37 out of 200\n",
      "Epoch [87/1000] Train Loss: 2.4931, Train Acc: 0.2800 Val Loss: 2.4943, Val Acc: 0.2544\n",
      "EarlyStopping counter: 38 out of 200\n",
      "Epoch [88/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 39 out of 200\n",
      "Epoch [89/1000] Train Loss: 2.4931, Train Acc: 0.3162 Val Loss: 2.4943, Val Acc: 0.2697\n",
      "EarlyStopping counter: 40 out of 200\n",
      "Epoch [90/1000] Train Loss: 2.4931, Train Acc: 0.3200 Val Loss: 2.4943, Val Acc: 0.2697\n",
      "EarlyStopping counter: 41 out of 200\n",
      "Epoch [91/1000] Train Loss: 2.4931, Train Acc: 0.3238 Val Loss: 2.4943, Val Acc: 0.2697\n",
      "EarlyStopping counter: 42 out of 200\n",
      "Epoch [92/1000] Train Loss: 2.4931, Train Acc: 0.3019 Val Loss: 2.4943, Val Acc: 0.2478\n",
      "EarlyStopping counter: 43 out of 200\n",
      "Epoch [93/1000] Train Loss: 2.4931, Train Acc: 0.2937 Val Loss: 2.4943, Val Acc: 0.2478\n",
      "EarlyStopping counter: 44 out of 200\n",
      "Epoch [94/1000] Train Loss: 2.4931, Train Acc: 0.2986 Val Loss: 2.4943, Val Acc: 0.2522\n",
      "EarlyStopping counter: 45 out of 200\n",
      "Epoch [95/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2544\n",
      "EarlyStopping counter: 46 out of 200\n",
      "Epoch [96/1000] Train Loss: 2.4931, Train Acc: 0.2877 Val Loss: 2.4943, Val Acc: 0.2478\n",
      "EarlyStopping counter: 47 out of 200\n",
      "Epoch [97/1000] Train Loss: 2.4931, Train Acc: 0.2860 Val Loss: 2.4943, Val Acc: 0.2478\n",
      "EarlyStopping counter: 48 out of 200\n",
      "Epoch [98/1000] Train Loss: 2.4931, Train Acc: 0.2904 Val Loss: 2.4943, Val Acc: 0.2522\n",
      "EarlyStopping counter: 49 out of 200\n",
      "Epoch [99/1000] Train Loss: 2.4931, Train Acc: 0.2948 Val Loss: 2.4943, Val Acc: 0.2544\n",
      "EarlyStopping counter: 50 out of 200\n",
      "Epoch [100/1000] Train Loss: 2.4931, Train Acc: 0.3036 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 51 out of 200\n",
      "Epoch [101/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 52 out of 200\n",
      "Epoch [102/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 53 out of 200\n",
      "Epoch [103/1000] Train Loss: 2.4931, Train Acc: 0.2981 Val Loss: 2.4943, Val Acc: 0.2654\n",
      "EarlyStopping counter: 54 out of 200\n",
      "Epoch [104/1000] Train Loss: 2.4931, Train Acc: 0.2986 Val Loss: 2.4943, Val Acc: 0.2632\n",
      "EarlyStopping counter: 55 out of 200\n",
      "Epoch [105/1000] Train Loss: 2.4931, Train Acc: 0.2942 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 56 out of 200\n",
      "Epoch [106/1000] Train Loss: 2.4931, Train Acc: 0.2948 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 57 out of 200\n",
      "Epoch [107/1000] Train Loss: 2.4931, Train Acc: 0.2948 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 58 out of 200\n",
      "Epoch [108/1000] Train Loss: 2.4931, Train Acc: 0.2937 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 59 out of 200\n",
      "Epoch [109/1000] Train Loss: 2.4931, Train Acc: 0.2942 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 60 out of 200\n",
      "Epoch [110/1000] Train Loss: 2.4931, Train Acc: 0.2942 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 61 out of 200\n",
      "Epoch [111/1000] Train Loss: 2.4931, Train Acc: 0.2942 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 62 out of 200\n",
      "Epoch [112/1000] Train Loss: 2.4931, Train Acc: 0.2948 Val Loss: 2.4943, Val Acc: 0.2566\n",
      "EarlyStopping counter: 63 out of 200\n",
      "Epoch [113/1000] Train Loss: 2.4931, Train Acc: 0.2953 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 64 out of 200\n",
      "Epoch [114/1000] Train Loss: 2.4931, Train Acc: 0.2975 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 65 out of 200\n",
      "Epoch [115/1000] Train Loss: 2.4931, Train Acc: 0.2981 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 66 out of 200\n",
      "Epoch [116/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 67 out of 200\n",
      "Epoch [117/1000] Train Loss: 2.4931, Train Acc: 0.2986 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 68 out of 200\n",
      "Epoch [118/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 69 out of 200\n",
      "Epoch [119/1000] Train Loss: 2.4931, Train Acc: 0.2986 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 70 out of 200\n",
      "Epoch [120/1000] Train Loss: 2.4931, Train Acc: 0.2986 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 71 out of 200\n",
      "Epoch [121/1000] Train Loss: 2.4931, Train Acc: 0.2981 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 72 out of 200\n",
      "Epoch [122/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 73 out of 200\n",
      "Epoch [123/1000] Train Loss: 2.4931, Train Acc: 0.2981 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 74 out of 200\n",
      "Epoch [124/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 75 out of 200\n",
      "Epoch [125/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 76 out of 200\n",
      "Epoch [126/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 77 out of 200\n",
      "Epoch [127/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 78 out of 200\n",
      "Epoch [128/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 79 out of 200\n",
      "Epoch [129/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 80 out of 200\n",
      "Epoch [130/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 81 out of 200\n",
      "Epoch [131/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 82 out of 200\n",
      "Epoch [132/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 83 out of 200\n",
      "Epoch [133/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 84 out of 200\n",
      "Epoch [134/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 85 out of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 86 out of 200\n",
      "Epoch [136/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 87 out of 200\n",
      "Epoch [137/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 88 out of 200\n",
      "Epoch [138/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 89 out of 200\n",
      "Epoch [139/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 90 out of 200\n",
      "Epoch [140/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 91 out of 200\n",
      "Epoch [141/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 92 out of 200\n",
      "Epoch [142/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 93 out of 200\n",
      "Epoch [143/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 94 out of 200\n",
      "Epoch [144/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 95 out of 200\n",
      "Epoch [145/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 96 out of 200\n",
      "Epoch [146/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 97 out of 200\n",
      "Epoch [147/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 98 out of 200\n",
      "Epoch [148/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 99 out of 200\n",
      "Epoch [149/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 100 out of 200\n",
      "Epoch [150/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 101 out of 200\n",
      "Epoch [151/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 102 out of 200\n",
      "Epoch [152/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 103 out of 200\n",
      "Epoch [153/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 104 out of 200\n",
      "Epoch [154/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 105 out of 200\n",
      "Epoch [155/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 106 out of 200\n",
      "Epoch [156/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 107 out of 200\n",
      "Epoch [157/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 108 out of 200\n",
      "Epoch [158/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 109 out of 200\n",
      "Epoch [159/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 110 out of 200\n",
      "Epoch [160/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 111 out of 200\n",
      "Epoch [161/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 112 out of 200\n",
      "Epoch [162/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 113 out of 200\n",
      "Epoch [163/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 114 out of 200\n",
      "Epoch [164/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 115 out of 200\n",
      "Epoch [165/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 116 out of 200\n",
      "Epoch [166/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 117 out of 200\n",
      "Epoch [167/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 118 out of 200\n",
      "Epoch [168/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 119 out of 200\n",
      "Epoch [169/1000] Train Loss: 2.4931, Train Acc: 0.2992 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 120 out of 200\n",
      "Epoch [170/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 121 out of 200\n",
      "Epoch [171/1000] Train Loss: 2.4931, Train Acc: 0.2975 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 122 out of 200\n",
      "Epoch [172/1000] Train Loss: 2.4931, Train Acc: 0.2975 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 123 out of 200\n",
      "Epoch [173/1000] Train Loss: 2.4931, Train Acc: 0.2975 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 124 out of 200\n",
      "Epoch [174/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 125 out of 200\n",
      "Epoch [175/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 126 out of 200\n",
      "Epoch [176/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 127 out of 200\n",
      "Epoch [177/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 128 out of 200\n",
      "Epoch [178/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 129 out of 200\n",
      "Epoch [179/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 130 out of 200\n",
      "Epoch [180/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 131 out of 200\n",
      "Epoch [181/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 132 out of 200\n",
      "Epoch [182/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 133 out of 200\n",
      "Epoch [183/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 134 out of 200\n",
      "Epoch [184/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 135 out of 200\n",
      "Epoch [185/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 136 out of 200\n",
      "Epoch [186/1000] Train Loss: 2.4931, Train Acc: 0.2970 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 137 out of 200\n",
      "Epoch [187/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 138 out of 200\n",
      "Epoch [188/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 139 out of 200\n",
      "Epoch [189/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 140 out of 200\n",
      "Epoch [190/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 141 out of 200\n",
      "Epoch [191/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 142 out of 200\n",
      "Epoch [192/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 143 out of 200\n",
      "Epoch [193/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 144 out of 200\n",
      "Epoch [194/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 145 out of 200\n",
      "Epoch [195/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 146 out of 200\n",
      "Epoch [196/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 147 out of 200\n",
      "Epoch [197/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 148 out of 200\n",
      "Epoch [198/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 149 out of 200\n",
      "Epoch [199/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 150 out of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 151 out of 200\n",
      "Epoch [201/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 152 out of 200\n",
      "Epoch [202/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 153 out of 200\n",
      "Epoch [203/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 154 out of 200\n",
      "Epoch [204/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 155 out of 200\n",
      "Epoch [205/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 156 out of 200\n",
      "Epoch [206/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 157 out of 200\n",
      "Epoch [207/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 158 out of 200\n",
      "Epoch [208/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 159 out of 200\n",
      "Epoch [209/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 160 out of 200\n",
      "Epoch [210/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 161 out of 200\n",
      "Epoch [211/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 162 out of 200\n",
      "Epoch [212/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 163 out of 200\n",
      "Epoch [213/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 164 out of 200\n",
      "Epoch [214/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 165 out of 200\n",
      "Epoch [215/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 166 out of 200\n",
      "Epoch [216/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 167 out of 200\n",
      "Epoch [217/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 168 out of 200\n",
      "Epoch [218/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 169 out of 200\n",
      "Epoch [219/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 170 out of 200\n",
      "Epoch [220/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 171 out of 200\n",
      "Epoch [221/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 172 out of 200\n",
      "Epoch [222/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 173 out of 200\n",
      "Epoch [223/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 174 out of 200\n",
      "Epoch [224/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 175 out of 200\n",
      "Epoch [225/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 176 out of 200\n",
      "Epoch [226/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 177 out of 200\n",
      "Epoch [227/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 178 out of 200\n",
      "Epoch [228/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 179 out of 200\n",
      "Epoch [229/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 180 out of 200\n",
      "Epoch [230/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 181 out of 200\n",
      "Epoch [231/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 182 out of 200\n",
      "Epoch [232/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 183 out of 200\n",
      "Epoch [233/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 184 out of 200\n",
      "Epoch [234/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 185 out of 200\n",
      "Epoch [235/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 186 out of 200\n",
      "Epoch [236/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 187 out of 200\n",
      "Epoch [237/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 188 out of 200\n",
      "Epoch [238/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 189 out of 200\n",
      "Epoch [239/1000] Train Loss: 2.4931, Train Acc: 0.2964 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 190 out of 200\n",
      "Epoch [240/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 191 out of 200\n",
      "Epoch [241/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 192 out of 200\n",
      "Epoch [242/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 193 out of 200\n",
      "Epoch [243/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 194 out of 200\n",
      "Epoch [244/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 195 out of 200\n",
      "Epoch [245/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 196 out of 200\n",
      "Epoch [246/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 197 out of 200\n",
      "Epoch [247/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 198 out of 200\n",
      "Epoch [248/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 199 out of 200\n",
      "Epoch [249/1000] Train Loss: 2.4931, Train Acc: 0.2959 Val Loss: 2.4943, Val Acc: 0.2588\n",
      "EarlyStopping counter: 200 out of 200\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Parameters\n",
    "num_epochs = 1000\n",
    "balanced_epochs = 500  # Number of epochs with balanced class weights\n",
    "unbalanced_epochs = num_epochs - balanced_epochs  # Remaining epochs for unbalanced training\n",
    "\n",
    "# Metrics storage\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Early Stopping Parameters\n",
    "best_val_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "patience = 200\n",
    "trigger_times = 0\n",
    "\n",
    "# Start Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct_predictions, total_predictions = 0.0, 0, 0\n",
    "\n",
    "    # Set Criterion Based on Epoch\n",
    "    if epoch < balanced_epochs:\n",
    "        criterion = HingeLoss(C=C, class_weights=class_weights)  # Balanced weights\n",
    "    else:\n",
    "        criterion = HingeLoss(C=C, class_weights=None)  # Uniform weights\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_predictions\n",
    "    epoch_acc = correct_predictions / total_predictions\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss, val_correct_predictions, val_total_predictions = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct_predictions += (predicted == labels).sum().item()\n",
    "            val_total_predictions += labels.size(0)\n",
    "\n",
    "    val_epoch_loss = val_running_loss / val_total_predictions\n",
    "    val_epoch_acc = val_correct_predictions / val_total_predictions\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_acc)\n",
    "\n",
    "    scheduler.step(val_epoch_loss)  # Adjust learning rate based on validation loss\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_epoch_acc > best_val_acc:\n",
    "        best_val_acc = val_epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f'EarlyStopping counter: {trigger_times} out of {patience}')\n",
    "        if trigger_times >= patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a97f9-ec64-4d61-bb00-ab708631767c",
   "metadata": {
    "id": "5a4a97f9-ec64-4d61-bb00-ab708631767c"
   },
   "source": [
    "## Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7f9c1-9ac4-4bd0-b2fe-f7ea760b4359",
   "metadata": {
    "id": "77e7f9c1-9ac4-4bd0-b2fe-f7ea760b4359"
   },
   "source": [
    "#### Compute accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "726fd227-3123-4867-8efe-c53928861263",
   "metadata": {
    "id": "726fd227-3123-4867-8efe-c53928861263"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): True labels.\n",
    "        y_pred (list): Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy score.\n",
    "    \"\"\"\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    total = len(y_true)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252eba3-498b-436e-af2b-05612d3f4e44",
   "metadata": {
    "id": "2252eba3-498b-436e-af2b-05612d3f4e44"
   },
   "source": [
    "### Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e9bce64-c03b-4725-b3a2-5d56157e46fe",
   "metadata": {
    "id": "3e9bce64-c03b-4725-b3a2-5d56157e46fe"
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y_true, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Computes the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): True labels.\n",
    "        y_pred (list): Predicted labels.\n",
    "        labels (list): List of unique labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Nested dictionary representing the confusion matrix.\n",
    "              Outer keys are true labels, inner keys are predicted labels.\n",
    "    \"\"\"\n",
    "    cm = {true_label: {pred_label: 0 for pred_label in labels} for true_label in labels}\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true in cm and pred in cm[true]:\n",
    "            cm[true][pred] += 1\n",
    "        else:\n",
    "            # Handle unexpected labels\n",
    "            pass\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c12ef-0ff2-4730-b1c3-ec86a8c6dfa4",
   "metadata": {
    "id": "623c12ef-0ff2-4730-b1c3-ec86a8c6dfa4"
   },
   "source": [
    "### Precision, Recall and F1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee23eec4-606f-458b-bb03-d6981c60ad61",
   "metadata": {
    "id": "ee23eec4-606f-458b-bb03-d6981c60ad61"
   },
   "outputs": [],
   "source": [
    "def compute_classification_metrics(cm, labels):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and F1-score for each class.\n",
    "\n",
    "    Args:\n",
    "        cm (dict): Confusion matrix.\n",
    "        labels (list): List of unique labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Nested dictionary with metrics for each label.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    for label in labels:\n",
    "        TP = cm[label][label]\n",
    "        FP = sum(cm[other][label] for other in labels if other != label)\n",
    "        FN = sum(cm[label][other] for other in labels if other != label)\n",
    "        TN = sum(cm[other_true][other_pred] for other_true in labels for other_pred in labels\n",
    "                 if other_true != label and other_pred != label)\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        metrics[label] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'support': TP + FN\n",
    "        }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e2077d-881a-4ab3-9ca2-03cb5eb8da73",
   "metadata": {
    "id": "42e2077d-881a-4ab3-9ca2-03cb5eb8da73"
   },
   "source": [
    "### Macro and weighted average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd66d6c-c31b-49bd-8d33-122527eee4e5",
   "metadata": {
    "id": "edd66d6c-c31b-49bd-8d33-122527eee4e5"
   },
   "outputs": [],
   "source": [
    "def compute_averages(metrics, labels):\n",
    "    \"\"\"\n",
    "    Computes macro and weighted averages for precision, recall, and F1-score.\n",
    "\n",
    "    Args:\n",
    "        metrics (dict): Classification metrics for each label.\n",
    "        labels (list): List of unique labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing macro and weighted averages.\n",
    "    \"\"\"\n",
    "    macro = {'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "    weighted = {'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "    total_support = 0\n",
    "\n",
    "    for label in labels:\n",
    "        macro['precision'] += metrics[label]['precision']\n",
    "        macro['recall'] += metrics[label]['recall']\n",
    "        macro['f1_score'] += metrics[label]['f1_score']\n",
    "\n",
    "        weighted['precision'] += metrics[label]['precision'] * metrics[label]['support']\n",
    "        weighted['recall'] += metrics[label]['recall'] * metrics[label]['support']\n",
    "        weighted['f1_score'] += metrics[label]['f1_score'] * metrics[label]['support']\n",
    "        total_support += metrics[label]['support']\n",
    "\n",
    "    macro_avg = {k: v / len(labels) for k, v in macro.items()}\n",
    "    weighted_avg = {k: v / total_support for k, v in weighted.items()}\n",
    "\n",
    "    return {'macro_avg': macro_avg, 'weighted_avg': weighted_avg}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b3014-1807-4498-a211-9a9ec22f3b3b",
   "metadata": {
    "id": "230b3014-1807-4498-a211-9a9ec22f3b3b"
   },
   "source": [
    "## Combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50ad1123-2526-4735-a82c-e2db074f5043",
   "metadata": {
    "id": "50ad1123-2526-4735-a82c-e2db074f5043"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device, int_to_label):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided data_loader without using scikit-learn.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained PyTorch model.\n",
    "        data_loader (DataLoader): DataLoader for the dataset.\n",
    "        device (torch.device): Device to run the evaluation on.\n",
    "        int_to_label (dict): Dictionary to decode integer labels back to original labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Decode labels back to original\n",
    "    y_pred = [int_to_label[pred] for pred in all_preds]\n",
    "    y_true = [int_to_label[label] for label in all_labels]\n",
    "\n",
    "    # Get list of unique labels\n",
    "    unique_labels = sorted(int_to_label.values())\n",
    "\n",
    "    # Compute Confusion Matrix\n",
    "    cm = compute_confusion_matrix(y_true, y_pred, unique_labels)\n",
    "\n",
    "    # Compute Classification Metrics\n",
    "    metrics = compute_classification_metrics(cm, unique_labels)\n",
    "    averages = compute_averages(metrics, unique_labels)\n",
    "\n",
    "    # Print Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label in unique_labels:\n",
    "        print(f\"Class: {label}\")\n",
    "        print(f\"  Precision: {metrics[label]['precision']:.2f}\")\n",
    "        print(f\"  Recall:    {metrics[label]['recall']:.2f}\")\n",
    "        print(f\"  F1-Score:  {metrics[label]['f1_score']:.2f}\")\n",
    "        print(f\"  Support:   {metrics[label]['support']}\")\n",
    "        print()\n",
    "\n",
    "    print(\"Macro Average:\")\n",
    "    for metric, value in averages['macro_avg'].items():\n",
    "        print(f\"  {metric.capitalize()}: {value:.2f}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Weighted Average:\")\n",
    "    for metric, value in averages['weighted_avg'].items():\n",
    "        print(f\"  {metric.capitalize()}: {value:.2f}\")\n",
    "    print()\n",
    "\n",
    "    # Convert Confusion Matrix to List of Lists for plotting\n",
    "    cm_matrix = []\n",
    "    for true_label in unique_labels:\n",
    "        row = []\n",
    "        for pred_label in unique_labels:\n",
    "            row.append(cm[true_label][pred_label])\n",
    "        cm_matrix.append(row)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=unique_labels,\n",
    "                yticklabels=unique_labels)\n",
    "    plt.title('Confusion Matrix - SVM')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "    # Compute and Print Accuracy\n",
    "    accuracy = compute_accuracy(y_true, y_pred)\n",
    "    print(f\"SVM Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74ec30-68a4-40b1-85d6-4d899b1b7f48",
   "metadata": {
    "id": "6b74ec30-68a4-40b1-85d6-4d899b1b7f48"
   },
   "source": [
    "## Evaluation report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be62fd65-73df-46b6-a4b5-dc9678f8140b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "be62fd65-73df-46b6-a4b5-dc9678f8140b",
    "outputId": "6388b310-53ae-4ba8-d9b1-92afd4d4eb01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "Class: business\n",
      "  Precision: 1.00\n",
      "  Recall:    0.18\n",
      "  F1-Score:  0.30\n",
      "  Support:   90\n",
      "\n",
      "Class: entertainment\n",
      "  Precision: 0.98\n",
      "  Recall:    0.58\n",
      "  F1-Score:  0.73\n",
      "  Support:   86\n",
      "\n",
      "Class: international\n",
      "  Precision: 0.70\n",
      "  Recall:    0.92\n",
      "  F1-Score:  0.79\n",
      "  Support:   98\n",
      "\n",
      "Class: science-technology\n",
      "  Precision: 1.00\n",
      "  Recall:    0.55\n",
      "  F1-Score:  0.71\n",
      "  Support:   98\n",
      "\n",
      "Class: sports\n",
      "  Precision: 0.40\n",
      "  Recall:    0.99\n",
      "  F1-Score:  0.57\n",
      "  Support:   84\n",
      "\n",
      "Macro Average:\n",
      "  Precision: 0.82\n",
      "  Recall: 0.64\n",
      "  F1_score: 0.62\n",
      "\n",
      "Weighted Average:\n",
      "  Precision: 0.82\n",
      "  Recall: 0.64\n",
      "  F1_score: 0.63\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6425\n"
     ]
    }
   ],
   "source": [
    "accuracy_nn = evaluate_model(model, test_loader, device, int_to_label)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
